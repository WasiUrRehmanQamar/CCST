{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Use GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hide Warnings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio torchinfo einops scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U mne==1.0.0 scipy==1.13.1 numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to file\n",
    "file_path1 = '/kaggle/input/PhysioNet.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "file_path = file_path1\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Check basic information\n",
    "print(f\"Loaded {len(data)} subjects.\")\n",
    "print(f\"First subject summary:\\n{data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "file_path = file_path1\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Print basic information about the dataset\n",
    "print(f\"Number of subjects loaded: {len(data)}\")\n",
    "\n",
    "for idx, epochs in enumerate(data):\n",
    "    print(f\"\\n--- Subject {idx + 1} ---\")\n",
    "    print(f\"Shape of raw data: {epochs.get_data().shape}\")  # (n_epochs, n_channels, n_times)\n",
    "    print(f\"Sampling frequency: {epochs.info['sfreq']} Hz\")\n",
    "    print(f\"Number of channels: {len(epochs.info['ch_names'])}\")\n",
    "    print(f\"Channel names: {epochs.info['ch_names']}\")\n",
    "    print(f\"Event types: {set(event[2] for event in epochs.events)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from einops import rearrange\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import LeaveOneGroupOut, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import math\n",
    "import csv\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut\n",
    "\n",
    "from einops.layers.torch import Rearrange\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------\n",
    "# 0) Basic imports & seed\n",
    "# -----------------------\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# -----------------------\n",
    "# 1) Pad & resize helper\n",
    "# -----------------------\n",
    "def pad_and_resize_eeg(eeg_2d: np.ndarray, target_h: int = 64, target_w: int = 201) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Zero-pad or truncate EEG trial to (target_h, target_w)\n",
    "    eeg_2d shape: (channels, time_samples)\n",
    "    \"\"\"\n",
    "    out = np.zeros((target_h, target_w), dtype=eeg_2d.dtype)\n",
    "    h, w = eeg_2d.shape\n",
    "    used_h = min(h, target_h)\n",
    "    used_w = min(w, target_w)\n",
    "    out[:used_h, :used_w] = eeg_2d[:used_h, :used_w]\n",
    "    return out\n",
    "\n",
    "# -----------------------\n",
    "# 2) Load & preprocess\n",
    "# -----------------------\n",
    "def load_and_preprocess_data(\n",
    "    pickle_path: str,\n",
    "    target_h: int = 64,\n",
    "    target_w: int = 641,\n",
    "    l_freq: float = 7.0,\n",
    "    h_freq: float = 30.0\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load list-of-MNE-Epochs pickle and return standardized arrays.\n",
    "    Returns:\n",
    "        all_X: (N_trials, 1, target_h, target_w) float32\n",
    "        all_y: (N_trials,) int64 with labels 0/1\n",
    "        all_subjects: (N_trials,) subject index\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from: {pickle_path}\")\n",
    "    with open(pickle_path, \"rb\") as f:\n",
    "        raw_data = pickle.load(f)  # list of MNE Epochs objects (one per subject)\n",
    "\n",
    "    all_X_list = []\n",
    "    all_y_list = []\n",
    "    all_subj_list = []\n",
    "\n",
    "    for subj_idx, epochs in enumerate(raw_data):\n",
    "        # Some Epochs objects may not have filter method available if already filtered; guard with try/catch\n",
    "        try:\n",
    "            epochs = epochs.copy().filter(l_freq=l_freq, h_freq=h_freq)\n",
    "        except Exception:\n",
    "            # if filtering fails, continue without throwing (user can prefilter)\n",
    "            pass\n",
    "\n",
    "        X = epochs.get_data()  # (trials, channels, time_samples)\n",
    "        events = epochs.events  # (trials, 3) usually [sample, 0, event_id]\n",
    "        # event_id likely in column 2; guard for shape\n",
    "        if events.shape[1] >= 3:\n",
    "            y_raw = events[:, 2]\n",
    "        else:\n",
    "            # fallback if events stored differently\n",
    "            y_raw = epochs.events[:, -1]\n",
    "\n",
    "        # Map event codes to labels: 1->0, 2->1, 3->2, 4->3\n",
    "        # This includes all observed events {1,2,3,4} as 4 classes (left_hand, right_hand, both_hands, feet)\n",
    "        y_mapped = np.zeros_like(y_raw) - 1  # Initialize to -1 for invalid\n",
    "        y_mapped[y_raw == 1] = 0\n",
    "        y_mapped[y_raw == 2] = 1\n",
    "        y_mapped[y_raw == 3] = 2\n",
    "        y_mapped[y_raw == 4] = 3\n",
    "        # Filter only valid labels (0-3 after mapping)\n",
    "        valid_mask = (y_mapped >= 0) & (y_mapped < 4)\n",
    "        X = X[valid_mask]\n",
    "        y_mapped = y_mapped[valid_mask]\n",
    "\n",
    "        # resize each trial to (target_h, target_w)\n",
    "        padded = [pad_and_resize_eeg(trial, target_h, target_w) for trial in X]\n",
    "        padded = np.stack(padded, axis=0)  # (trials, channels, time)\n",
    "\n",
    "        padded = np.expand_dims(padded, axis=1)  # (trials, 1, channels, time)\n",
    "        all_X_list.append(padded)\n",
    "        all_y_list.append(y_mapped)\n",
    "        all_subj_list += [subj_idx] * len(y_mapped)\n",
    "\n",
    "        # print(f\"Subject {subj_idx+1}: trials={padded.shape[0]}, shape(per_trial)={(1,target_h,target_w)}\")\n",
    "\n",
    "    all_X = np.concatenate(all_X_list, axis=0)\n",
    "    all_y = np.concatenate(all_y_list, axis=0)\n",
    "    all_subjects = np.array(all_subj_list)\n",
    "\n",
    "    # Standardize across channels*time per-trial (zero mean, unit var)\n",
    "    nsamples, _, H, W = all_X.shape\n",
    "    scaler = StandardScaler()\n",
    "    X_flat = all_X.reshape(nsamples, -1)\n",
    "    X_scaled = scaler.fit_transform(X_flat)\n",
    "    all_X = X_scaled.reshape(nsamples, 1, H, W).astype(np.float32)\n",
    "\n",
    "    # print(f\"Total trials: {all_X.shape[0]}, Subjects: {len(np.unique(all_subjects))}\")\n",
    "    return all_X, all_y.astype(np.int64), all_subjects\n",
    "\n",
    "# -----------------------\n",
    "# 3) Dataset without augmentation\n",
    "# -----------------------\n",
    "class MultiSubjectBCIDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, augment: bool = False):\n",
    "        \"\"\"\n",
    "        X: (N, 1, C, T)\n",
    "        y: (N,)\n",
    "        augment: Kept for compatibility, but no augmentations are applied\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_np = self.X[idx]  # (1, C, T)\n",
    "        label = int(self.y[idx])\n",
    "        x_t = torch.from_numpy(x_np).float()\n",
    "        return x_t, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# -----------------------\n",
    "# 4) Window helpers (Swin1D utils)\n",
    "# -----------------------\n",
    "def pad_sequence_1d(x: torch.Tensor, window_size: int):\n",
    "    B, L, C = x.shape\n",
    "    remainder = L % window_size\n",
    "    if remainder == 0:\n",
    "        return x, L, 0\n",
    "    pad_len = window_size - remainder\n",
    "    pad_vec = torch.zeros(B, pad_len, C, dtype=x.dtype, device=x.device)\n",
    "    x_padded = torch.cat([x, pad_vec], dim=1)\n",
    "    return x_padded, L, pad_len\n",
    "\n",
    "def window_partition_1d(x: torch.Tensor, window_size: int):\n",
    "    B, L, C = x.shape\n",
    "    x_padded, orig_L, pad_len = pad_sequence_1d(x, window_size)\n",
    "    Bp, Lp, Cp = x_padded.shape\n",
    "    num_windows = Lp // window_size\n",
    "    x_padded = x_padded.view(Bp, num_windows, window_size, Cp)\n",
    "    x_windows = x_padded.reshape(Bp * num_windows, window_size, Cp)\n",
    "    return x_windows, (orig_L, pad_len, num_windows)\n",
    "\n",
    "def window_reverse_1d(x_windows: torch.Tensor, window_size: int, pad_info):\n",
    "    orig_L, pad_len, num_windows = pad_info\n",
    "    BnW, WS, C = x_windows.shape\n",
    "    B = BnW // num_windows\n",
    "    x_reshaped = x_windows.view(B, num_windows, WS, C)\n",
    "    x_merged = x_reshaped.reshape(B, num_windows * WS, C)\n",
    "    if pad_len > 0:\n",
    "        x_merged = x_merged[:, :orig_L, :]\n",
    "    return x_merged\n",
    "\n",
    "def cyclic_shift_1d(x: torch.Tensor, shift_size: int):\n",
    "    return torch.roll(x, shifts=-shift_size, dims=1)\n",
    "\n",
    "def cyclic_shift_back_1d(x: torch.Tensor, shift_size: int):\n",
    "    return torch.roll(x, shifts=shift_size, dims=1)\n",
    "\n",
    "# -----------------------\n",
    "# 5) Attention & MLP\n",
    "# -----------------------\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim: int, num_heads: int, attn_dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.attn_drop = nn.Dropout(attn_dropout)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(attn_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, L, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, L, 3, self.num_heads, C // self.num_heads)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        out = (attn @ v).transpose(1, 2).reshape(B, L, C)\n",
    "        out = self.proj(out)\n",
    "        out = self.proj_drop(out)\n",
    "        return out\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim: int, hidden_dim: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# -----------------------\n",
    "# 6) Swin1D block and transformer\n",
    "# -----------------------\n",
    "class Swin1DBlock(nn.Module):\n",
    "    def __init__(self, dim: int, num_heads: int, window_size: int = 4, shift_size: int = 2, mlp_hidden: int = 128, attn_dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(dim)\n",
    "        self.attn = Attention(dim=dim, num_heads=num_heads, attn_dropout=attn_dropout)\n",
    "        self.ln2 = nn.LayerNorm(dim)\n",
    "        self.mlp = MLP(dim=dim, hidden_dim=mlp_hidden, dropout=attn_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, dim)\n",
    "        if self.shift_size > 0:\n",
    "            x = cyclic_shift_1d(x, self.shift_size)\n",
    "\n",
    "        x_windows, pad_info = window_partition_1d(x, self.window_size)\n",
    "\n",
    "        shortcut = x_windows\n",
    "        x_windows = self.ln1(x_windows)\n",
    "        x_windows = self.attn(x_windows)\n",
    "        x_windows = shortcut + x_windows\n",
    "\n",
    "        shortcut = x_windows\n",
    "        x_windows = self.ln2(x_windows)\n",
    "        x_windows = self.mlp(x_windows)\n",
    "        x_windows = shortcut + x_windows\n",
    "\n",
    "        x_merged = window_reverse_1d(x_windows, self.window_size, pad_info)\n",
    "        if self.shift_size > 0:\n",
    "            x_merged = cyclic_shift_back_1d(x_merged, self.shift_size)\n",
    "        return x_merged\n",
    "\n",
    "class Swin1DTransformer(nn.Module):\n",
    "    def __init__(self, dim: int = 64, num_layers: int = 3, num_heads: int = 4, mlp_hidden: int = 128, window_size: int = 4, attn_dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        blocks = []\n",
    "        for i in range(num_layers):\n",
    "            shift = window_size // 2 if (i % 2 == 1) else 0\n",
    "            blocks.append(Swin1DBlock(dim=dim, num_heads=num_heads, window_size=window_size, shift_size=shift, mlp_hidden=mlp_hidden, attn_dropout=attn_dropout))\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.norm(x)\n",
    "        x = x.mean(dim=1)  # average pool over sequence length\n",
    "        return x\n",
    "\n",
    "# -----------------------\n",
    "# 7) Positional embeddings\n",
    "# -----------------------\n",
    "def create_positional_embedding(mode: str, seq_len: int, dim: int):\n",
    "    if mode == 'none':\n",
    "        return None\n",
    "    elif mode == 'learnable':\n",
    "        pe = nn.Parameter(torch.zeros(1, seq_len, dim))\n",
    "        nn.init.trunc_normal_(pe, std=0.02)\n",
    "        return pe\n",
    "    elif mode == 'sine':\n",
    "        pe_np = np.zeros((seq_len, dim))\n",
    "        for pos in range(seq_len):\n",
    "            for i in range(0, dim, 2):\n",
    "                theta = pos / (10000 ** ((2 * i) / dim))\n",
    "                pe_np[pos, i]   = np.sin(theta)\n",
    "                if i+1 < dim:\n",
    "                    pe_np[pos, i+1] = np.cos(theta)\n",
    "        pe = torch.from_numpy(pe_np).float().unsqueeze(0)\n",
    "        return nn.Parameter(pe, requires_grad=False)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported pos emb mode\")\n",
    "\n",
    "# -----------------------\n",
    "# 8) Patch Embedding (dynamic for C and W)\n",
    "# -----------------------\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels: int, input_time_len: int, emb_size: int = 40, pool_kernel: int = 75, pool_stride: int = 15):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: number of EEG channels (e.g., 64)\n",
    "            input_time_len: number of time samples per trial (e.g., 201)\n",
    "            emb_size: output embedding dimension\n",
    "            pool_kernel/pool_stride: controls temporal downsampling -> determines seq_len\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Temporal conv (across time) -> keep channel dim intact (still in channel dim)\n",
    "        self.conv_temp = nn.Conv2d(1, 40, kernel_size=(1, 25), stride=(1, 1), padding=(0, 0))\n",
    "        # Spatial conv across electrodes: kernel height = in_channels -> collapses electrode dim to 1\n",
    "        self.conv_spat = nn.Conv2d(40, 40, kernel_size=(in_channels, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.bn = nn.BatchNorm2d(40)\n",
    "        self.act = nn.ELU()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(1, pool_kernel), stride=(1, pool_stride))\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        self.proj = nn.Conv2d(40, emb_size, kernel_size=(1,1), stride=(1,1))\n",
    "        self.rearrange = Rearrange('b e h w -> b (h w) e')  # will be (B, seq_len, emb_size)\n",
    "\n",
    "        # store params for computing seq_len\n",
    "        self.input_time_len = input_time_len\n",
    "        self.pool_kernel = pool_kernel\n",
    "        self.pool_stride = pool_stride\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, 1, C, T)\n",
    "        x = self.conv_temp(x)     # -> (B, 40, C, T-24)\n",
    "        x = self.conv_spat(x)     # -> (B, 40, 1, T-24)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)          # -> (B, 40, 1, Wp)\n",
    "        x = self.drop(x)\n",
    "        x = self.proj(x)          # -> (B, emb_size, 1, Wp)\n",
    "        x = self.rearrange(x)     # -> (B, seq_len=Wp, emb_size)\n",
    "        return x\n",
    "\n",
    "    def compute_seq_len(self):\n",
    "        # compute width after conv_temp (kernel 25, stride 1, no pad)\n",
    "        W1 = self.input_time_len - 25 + 1  # (T - kernel + 1)\n",
    "        # after pool: floor((W1 - pool_kernel)/pool_stride) + 1 if W1 >= pool_kernel else 0 or 1 (handle small sizes)\n",
    "        if W1 < self.pool_kernel:\n",
    "            # if smaller than kernel, pooling will return size 1 (PyTorch behavior: kernel > input -> kernel reduces to input length)\n",
    "            # but to be safe, set seq_len = 1\n",
    "            Wp = 1\n",
    "        else:\n",
    "            Wp = (W1 - self.pool_kernel) // self.pool_stride + 1\n",
    "            Wp = max(1, Wp)\n",
    "        return Wp\n",
    "\n",
    "# -----------------------\n",
    "# 9) Classification head & CCST\n",
    "# -----------------------\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim: int = 64, num_classes: int = 4, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "class CCST(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 64,\n",
    "        input_time_len: int = 201,\n",
    "        emb_size: int = 40,\n",
    "        swin_embedding_dim: int = 64,\n",
    "        num_swin_layers: int = 3,\n",
    "        num_heads: int = 4,\n",
    "        mlp_size: int = 128,\n",
    "        pos_emb_mode: str = 'learnable',\n",
    "        num_classes: int = 4\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.patch_embedding = PatchEmbedding(in_channels=in_channels, input_time_len=input_time_len, emb_size=emb_size)\n",
    "        seq_len = self.patch_embedding.compute_seq_len()\n",
    "        self.embedding_projection = nn.Linear(emb_size, swin_embedding_dim)\n",
    "        self.pos_encoding = create_positional_embedding(pos_emb_mode, seq_len=seq_len, dim=swin_embedding_dim)\n",
    "        self.transformer = Swin1DTransformer(dim=swin_embedding_dim, num_layers=num_swin_layers, num_heads=num_heads, mlp_hidden=mlp_size, window_size=4, attn_dropout=0.1)\n",
    "        self.classification_head = ClassificationHead(input_dim=swin_embedding_dim, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (B,1,C,T)\n",
    "        x = self.patch_embedding(x)             # [B, seq_len, emb_size]\n",
    "        x = self.embedding_projection(x)        # [B, seq_len, swin_embedding_dim]\n",
    "        if self.pos_encoding is not None:\n",
    "            x = x + self.pos_encoding[:, :x.size(1), :].to(x.device)\n",
    "        features = self.transformer(x)          # [B, swin_embedding_dim]\n",
    "        logits = self.classification_head(features)\n",
    "        return logits\n",
    "\n",
    "# -----------------------\n",
    "# 10) Experiment wrapper & LOSO training\n",
    "# -----------------------\n",
    "class HybridExP():\n",
    "    def __init__(self, pickle_path: str, device: str = 'cuda:0', batch_size: int = 64, n_epochs: int = 150):\n",
    "        self.pickle_path = pickle_path\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.patience = 10\n",
    "        self.lr = 3e-4\n",
    "        self.betas = (0.9, 0.999)\n",
    "        self.c_dim = 4\n",
    "\n",
    "        # Data fields (will be filled later)\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.subjects = None\n",
    "\n",
    "        # Model will be constructed after data loaded to get dims\n",
    "        self.model = None\n",
    "        self.criterion_cls = nn.CrossEntropyLoss().to(self.device)\n",
    "\n",
    "    def get_source_data(self):\n",
    "        X, y, subjects = load_and_preprocess_data(self.pickle_path, target_h=64, target_w=641, l_freq=7.0, h_freq=30.0)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.subjects = subjects\n",
    "        return X, y, subjects\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build model with dims matching data\n",
    "        _, _, C, T = self.X.shape\n",
    "        # print(f\"Building model for input channels={C}, time_len={T}\")\n",
    "        model = CCST(in_channels=C, input_time_len=T, emb_size=40, swin_embedding_dim=64, num_swin_layers=3, num_heads=4, mlp_size=128, pos_emb_mode='learnable', num_classes=self.c_dim)\n",
    "        model = model.to(self.device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        self.model = model\n",
    "\n",
    "    def train_fold(self, train_indices, val_indices, test_indices):\n",
    "        X_train_full = self.X[train_indices]\n",
    "        y_train_full = self.y[train_indices]\n",
    "        X_val = self.X[val_indices]\n",
    "        y_val = self.y[val_indices]\n",
    "        X_test = self.X[test_indices]\n",
    "        y_test = self.y[test_indices]\n",
    "\n",
    "        # small stratified split already done in caller; if val empty, fallback\n",
    "        train_ds = MultiSubjectBCIDataset(X_train_full, y_train_full, augment=False)\n",
    "        val_ds = MultiSubjectBCIDataset(X_val, y_val, augment=False)\n",
    "        test_ds = MultiSubjectBCIDataset(X_test, y_test, augment=False)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=self.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        test_loader = DataLoader(test_ds, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr, betas=self.betas)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=False)\n",
    "\n",
    "        best_val_acc = 0.0\n",
    "        best_state = None\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # Training\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for imgs, labels in train_loader:\n",
    "                imgs = imgs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(imgs)\n",
    "                loss = self.criterion_cls(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * imgs.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            train_loss = running_loss / max(1, total)\n",
    "            train_acc = correct / max(1, total)\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            with torch.no_grad():\n",
    "                for imgs, labels in val_loader:\n",
    "                    imgs = imgs.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "                    outputs = self.model(imgs)\n",
    "                    loss = self.criterion_cls(outputs, labels)\n",
    "                    val_loss += loss.item() * imgs.size(0)\n",
    "                    preds = outputs.argmax(dim=1)\n",
    "                    val_correct += (preds == labels).sum().item()\n",
    "                    val_total += labels.size(0)\n",
    "            if val_total == 0:\n",
    "                val_loss = 0.0\n",
    "                val_acc = 0.0\n",
    "            else:\n",
    "                val_loss = val_loss / val_total\n",
    "                val_acc = val_correct / val_total\n",
    "\n",
    "            scheduler.step(val_loss if val_total>0 else train_loss)\n",
    "\n",
    "            # Print progress every epoch\n",
    "            print(f\"Epoch {epoch+1}/{self.n_epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc*100:.2f}% | Val Loss: {val_loss:.4f} Acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "            # Early stopping based on val_acc\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_state = {k:v.cpu() for k,v in self.model.state_dict().items()}\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= self.patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "        # load best\n",
    "        if best_state is not None:\n",
    "            self.model.load_state_dict(best_state)\n",
    "\n",
    "        # Test\n",
    "        self.model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_loader:\n",
    "                imgs = imgs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                outputs = self.model(imgs)\n",
    "                loss = self.criterion_cls(outputs, labels)\n",
    "                test_loss += loss.item() * imgs.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                test_correct += (preds == labels).sum().item()\n",
    "                test_total += labels.size(0)\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        test_loss = test_loss / max(1, test_total)\n",
    "        test_acc = test_correct / max(1, test_total)\n",
    "        if len(all_preds) > 0:\n",
    "            all_preds = np.concatenate(all_preds)\n",
    "            all_labels = np.concatenate(all_labels)\n",
    "        else:\n",
    "            all_preds = np.array([])\n",
    "            all_labels = np.array([])\n",
    "\n",
    "        return test_acc, test_loss, all_labels, all_preds\n",
    "\n",
    "    def train_loso(self, out_csv: str = \"loso_results.csv\"):\n",
    "        X, y, subjects = self.get_source_data()\n",
    "        self.build_model()\n",
    "\n",
    "        logo = LeaveOneGroupOut()\n",
    "        test_accuracies = []\n",
    "        subject_ids = []\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "        # print(\"\\nStarting LOSO training ...\")\n",
    "        for train_idx, test_idx in logo.split(X, y, groups=subjects):\n",
    "            fold += 1\n",
    "            heldout_subj = subjects[test_idx[0]]\n",
    "            print(f\"\\n--- Fold {fold}: Test subject {heldout_subj+1}\")\n",
    "\n",
    "            # reseed per fold\n",
    "            set_seed(42 + fold)\n",
    "\n",
    "            # further split train into train/val stratified\n",
    "            X_train_full = X[train_idx]\n",
    "            y_train_full = y[train_idx]\n",
    "\n",
    "            unique_classes = len(np.unique(y_train_full))\n",
    "            if unique_classes < 4:\n",
    "                print(f\"Warning: fewer than 4 classes ({unique_classes} classes) in training set for this fold; skipping\")\n",
    "                continue\n",
    "\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, stratify=y_train_full, random_state=42+fold)\n",
    "\n",
    "            test_indices = test_idx\n",
    "            val_indices = np.arange(len(X))[:0] \n",
    "\n",
    "            # Build fresh model for this fold\n",
    "            self.build_model()\n",
    "            self.model.to(self.device)\n",
    "\n",
    "            # Prepare arrays for this fold\n",
    "            X_combined = np.concatenate([X_train, X_val, X[test_idx]], axis=0)\n",
    "            y_combined = np.concatenate([y_train, y_val, y[test_idx]], axis=0)\n",
    "            n_train = len(X_train)\n",
    "            n_val = len(X_val)\n",
    "            n_test = len(test_idx)\n",
    "\n",
    "            # Get absolute indices\n",
    "            train_indices = np.arange(0, n_train)\n",
    "            val_indices = np.arange(n_train, n_train + n_val)\n",
    "            test_indices_rel = np.arange(n_train + n_val, n_train + n_val + n_test)\n",
    "\n",
    "            # Temporarily set self.X/y to combined arrays to reuse train_fold\n",
    "            X_old, y_old = self.X, self.y\n",
    "            self.X, self.y = X_combined, y_combined\n",
    "\n",
    "            # Train fold\n",
    "            test_acc, test_loss, all_labels, all_preds = self.train_fold(train_indices, val_indices, test_indices_rel)\n",
    "\n",
    "            print(f\"Fold {fold} | Subject {heldout_subj+1} Test Acc: {test_acc*100:.2f} % | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "            test_accuracies.append(test_acc)\n",
    "            subject_ids.append(heldout_subj)\n",
    "\n",
    "            # Restore X/y\n",
    "            self.X, self.y = X_old, y_old\n",
    "\n",
    "            # Append results to CSV\n",
    "            with open(out_csv, mode='a', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                if f.tell() == 0:\n",
    "                    writer.writerow([\"subject_idx\", \"test_acc\", \"test_loss\", \"n_test_samples\"])\n",
    "                writer.writerow([int(heldout_subj), float(test_acc), float(test_loss), int(n_test)])\n",
    "\n",
    "        # Summary\n",
    "        if len(test_accuracies) > 0:\n",
    "            avg_test_acc = np.mean(test_accuracies) * 100.0\n",
    "        else:\n",
    "            avg_test_acc = 0.0\n",
    "        print(\"\\nLOSO Summary:\")\n",
    "        for sid, acc in zip(subject_ids, test_accuracies):\n",
    "            print(f\"Subject {sid+1}: {acc*100:.2f} %\")\n",
    "        print(f\"Average Test Accuracy: {avg_test_acc:.2f} %\")\n",
    "        # print(f\"Results saved to {out_csv}\")\n",
    "\n",
    "# -----------------------\n",
    "# 11) Main\n",
    "# -----------------------\n",
    "def main():\n",
    "    pickle_path = '/kaggle/input/PhysioNet.pkl'  # user-provided\n",
    "    out_csv = \"loso_results.csv\"\n",
    "    if os.path.exists(out_csv):\n",
    "        os.remove(out_csv)\n",
    "\n",
    "    exp = HybridExP(pickle_path=pickle_path, device='cuda:0', batch_size=72, n_epochs=150)\n",
    "    exp.train_loso(out_csv=out_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8476388,
     "sourceId": 13743640,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
